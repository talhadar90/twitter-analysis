{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab-twitter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtNki6MC1aZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt \n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1USXI3JK17Bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the Twitter Auth API\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNmEt_4c19hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('login.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU5DGGTs1W6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_consumer_key = \"8JswiIvok28rKbujIREXI66o7\"\n",
        "twitter_consumer_secret = \"o1q2JSoL4GXcNXgD615Om0cx9nQWMX8l3IhXoCeVQETMoYDAGN\"\n",
        "twitter_access_token = \"27828989-ikxjFx6sBq4ra6PcXAi0bo09ZnZRLES4epFEhV9vP\"\n",
        "twitter_access_secret = \"Emb172pIHReHbr8fCo5Qx5L6dE7LcusVbCTH3SrYl2g4m\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o92g8tVt2Cyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "authenticate = tweepy.OAuthHandler(twitter_consumer_key, twitter_consumer_secret)\n",
        "authenticate.set_access_token(twitter_access_token, twitter_access_secret)\n",
        "api = tweepy.API(authenticate, wait_on_rate_limit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utXrQeYE2FQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag1 = \"#ShiaGenocide\"\n",
        "\n",
        "tweets = api.search(q=tag1, lang=\"en\", count=100, tweet_mode=\"extended\")\n",
        "\n",
        "df = pd.DataFrame(t.__dict__ for t in tweets)\n",
        "\n",
        "df = df['full_text']\n",
        "\n",
        "df\n",
        "\n",
        "\n",
        "#hashtag2 = '#SHIA'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj5Gc9Vc3kq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This splits all the sentences up which makes it easier for us to work with\n",
        "\n",
        "all_sentences = []\n",
        "\n",
        "for word in df:\n",
        "    all_sentences.append(word)\n",
        "\n",
        "all_sentences\n",
        "#df1 = df.to_string()\n",
        "\n",
        "#df_split = df1.split()\n",
        "\n",
        "#df_split\n",
        "lines = list()\n",
        "for line in all_sentences:    \n",
        "    words = line.split()\n",
        "    for w in words: \n",
        "       lines.append(w)\n",
        "\n",
        "\n",
        "print(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zLudvBB3q6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing Punctuation\n",
        "\n",
        "lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]\n",
        "\n",
        "lines\n",
        "\n",
        "lines2 = []\n",
        "\n",
        "for word in lines:\n",
        "    if word != '':\n",
        "        lines2.append(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN0PNHGu3vW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is stemming the words to their root\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# The Snowball Stemmer requires that you pass a language parameter\n",
        "s_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "stem = []\n",
        "for word in lines2:\n",
        "    stem.append(s_stemmer.stem(word))\n",
        "    \n",
        "stem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4IH52pJ31xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing all Stop Words\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re  \n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "stem2 = []\n",
        "\n",
        "for word in stem:\n",
        "    if word not in nlp.Defaults.stop_words:\n",
        "        stem2.append(word)\n",
        "\n",
        "stem2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWLSfTci4q3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(stem2)\n",
        "df = df[0].value_counts()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH1-DJ9r5K2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "freqdoctor = FreqDist()\n",
        "\n",
        "for words in df:\n",
        "    freqdoctor[words] += 1\n",
        "\n",
        "freqdoctor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5W6bu675O2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwG6rvVx5QEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[:20,]\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(df.values, df.index, alpha=.8)\n",
        "plt.title('Top Words Overall')\n",
        "plt.ylabel('Word from Tweet', fontsize=12)\n",
        "plt.xlabel('Count of Words', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLhamxjc5c6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuSdG7W55eqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = \" \" \n",
        "stem2 = str1.join(lines2)\n",
        "\n",
        "stem2 = nlp(stem2)\n",
        "\n",
        "label = [(X.text, X.label_) for X in stem2.ents]\n",
        "\n",
        "df6 = pd.DataFrame(label, columns = ['Word','Entity'])\n",
        "\n",
        "df7 = df6.where(df6['Entity'] == 'ORG')\n",
        "\n",
        "df7 = df7['Word'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_yYJSK05j-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df7[:20,]\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(df.values, df.index, alpha=0.8)\n",
        "plt.title('Top Organizations Mentioned')\n",
        "plt.ylabel('Word from Tweet', fontsize=12)\n",
        "plt.xlabel('Count of Words', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzOeAxGs5p9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = \" \" \n",
        "stem2 = str1.join(lines2)\n",
        "\n",
        "stem2 = nlp(stem2)\n",
        "\n",
        "label = [(X.text, X.label_) for X in stem2.ents]\n",
        "\n",
        "df10 = pd.DataFrame(label, columns = ['Word','Entity'])\n",
        "\n",
        "df10 = df10.where(df10['Entity'] == 'PERSON')\n",
        "\n",
        "df11 = df10['Word'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCJTXSVe5rug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df11[:20,]\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(df.values, df.index, alpha=0.5)\n",
        "plt.title('Top People Mentioned')\n",
        "plt.ylabel('Word from Tweet', fontsize=12)\n",
        "plt.xlabel('Count of Words', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}